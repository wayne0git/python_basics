{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow2_gan_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTHveAJ0a+fjjxQYbdSvMm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvEXYgxVxsw4"
      },
      "source": [
        "## GAN Example to generate CIFAR-10 data\n",
        "- Ref - https://towardsdatascience.com/using-gans-to-generate-realistic-images-using-keras-and-the-cifar10-dataset-7dc6d23de994"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bszr_J7yxmzV"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Reshape, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjaYhOXI0HsO"
      },
      "source": [
        "### Constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3yhl9ly0KJ5"
      },
      "source": [
        "INPUT_SHAPE = (32, 32, 3)\n",
        "NOISE_DIM = 100\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PqfkOrryut3"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pwrmEOOyuCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61ad45f-392c-43db-e5ed-d7879c38f3fc"
      },
      "source": [
        "# Train -- (50000, 32, 32), (50000, )\n",
        "# Test -- (10000, 28, 28), (10000, )\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZaTxNhZzMsO"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIyKGDfZzMG_"
      },
      "source": [
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "X_test = (X_test.astype(np.float32) - 127.5) / 127.5"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1W4lbV8Y9b"
      },
      "source": [
        "### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEyTu6_A9A0J"
      },
      "source": [
        "def generate_real_img(n_samples):\n",
        "    x_real = X_train[np.random.randint(0, X_train.shape[0], n_samples)]\n",
        "    y_real = np.ones((n_samples, 1))\n",
        "\n",
        "    return x_real, y_real"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyiu1-cx8bCb"
      },
      "source": [
        "def generate_img_using_model(generator, n_samples):\n",
        "    noise = np.random.randn(n_samples, NOISE_DIM)\n",
        "\n",
        "    x_fake = generator.predict(noise)\n",
        "    y_fake = np.zeros((n_samples, 1))\n",
        "\n",
        "    return x_fake, y_fake"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6w6I7eSzjK8"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPICZv4gzdcE"
      },
      "source": [
        "# Discriminator\n",
        "def building_discriminator(input_shape=(32, 32, 3)):\n",
        "    model_d = Sequential()\n",
        "    # Layer 1 (32 * 32 * 3 -> 32 * 32 * 64)\n",
        "    model_d.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
        "    model_d.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 2 (32 * 32 * 64 -> 16 * 16 * 128)\n",
        "    model_d.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model_d.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 3 (16 * 16 * 128 -> 8 * 8 * 128)\n",
        "    model_d.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model_d.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 4 (8 * 8 * 128 -> 4 * 4 * 256)\n",
        "    model_d.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model_d.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Final Classification Layer (4 * 4 * 256 -> 4096 * 1)\n",
        "    model_d.add(Flatten())\n",
        "    model_d.add(Dropout(0.4))\n",
        "    model_d.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model_d.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model_d"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX3Y8FDW0_Lf"
      },
      "source": [
        "# Generator\n",
        "def building_generator(latent_dim):\n",
        "    model_g = Sequential()\n",
        "    # Layer 1 (100 * 1 -> 4 * 4 * 256)\n",
        "    model_g.add(Dense(256 * 4 * 4, input_shape=(latent_dim, )))\n",
        "    model_g.add(LeakyReLU(alpha=0.2))\n",
        "    model_g.add(Reshape((4, 4, 256)))\n",
        "\n",
        "    # Layer 2 (4 * 4 * 256 -> 8 * 8 * 128)\n",
        "    model_g.add(Conv2DTranspose(128, (4, 4), (2, 2), padding='same'))\n",
        "    model_g.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 3 (8 * 8 * 128 -> 16 * 16 * 128 -> 32 * 32 * 3)\n",
        "    model_g.add(Conv2DTranspose(128, (4, 4), (2, 2), padding='same'))\n",
        "    model_g.add(LeakyReLU(alpha=0.2))\n",
        "    model_g.add(Conv2DTranspose(128, (4, 4), (2, 2), padding='same'))\n",
        "    model_g.add(LeakyReLU(alpha=0.2))    \n",
        "    model_g.add(Conv2D(3, (3, 3), activation='tanh', padding='same'))\n",
        "\n",
        "    return model_g    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp5SibZX2WrK"
      },
      "source": [
        "def building_gan(generator, discriminator):\n",
        "    gan = Sequential()\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "\n",
        "    # Train the generator to make discriminator output real result\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\n",
        "    return gan"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuYZZm3q4R2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3274f22e-9f4d-4455-814b-9292981436f4"
      },
      "source": [
        "# Create GAN Model\n",
        "gen = building_generator(NOISE_DIM)\n",
        "dis = building_discriminator(INPUT_SHAPE)\n",
        "gan = building_gan(gen, dis)\n",
        "gan.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_3 (Sequential)    (None, 32, 32, 3)         1466115   \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 1)                 522497    \n",
            "=================================================================\n",
            "Total params: 1,988,612\n",
            "Trainable params: 1,466,115\n",
            "Non-trainable params: 522,497\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2GI8CK85Fcq"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPxSKBHw4nH6"
      },
      "source": [
        "def training_gan(gan_model, discriminator, generator, batch_size=256, epochs=100):\n",
        "    for epoch in range(epochs):\n",
        "        for step in range(X_train.shape[0] // batch_size):\n",
        "            # Get real and fake image data\n",
        "            X_real, y_real = generate_real_img(batch_size)\n",
        "            X_fake, y_fake = generate_img_using_model(generator, batch_size)\n",
        "\n",
        "            # Concatenate to get training data\n",
        "            X_batch = np.concatenate([X_real, X_fake], axis=0)\n",
        "            y_batch = np.concatenate([y_real, y_fake], axis=0)\n",
        "\n",
        "            # Train discriminator\n",
        "            d_loss, d_acc = discriminator.train_on_batch(X_batch, y_batch)\n",
        "\n",
        "            # Generate noise input for GAN training\n",
        "            X_gan = np.random.randn(batch_size, NOISE_DIM)\n",
        "            y_gan = np.ones((batch_size, 1))\n",
        "\n",
        "            # Train GAN (With fixed discriminator)\n",
        "            gan_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "            # Print loss info at each epoch end\n",
        "            print('Training progress in epoch #%d step #%d, discriminator loss=%.3f , generator loss=%.3f' % (epoch, step, d_loss, gan_loss))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKsMrS-ZC7Fx"
      },
      "source": [
        "training_gan(gan, dis, gen, BATCH_SIZE, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCAE--41Dfc_"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1367Gi2EGOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75629f4b-5e6b-49dd-dbc5-bfcf2758de2a"
      },
      "source": [
        "# Evaluate Discriminator\n",
        "X_real, y_real = generate_real_img(BATCH_SIZE)\n",
        "_, acc_real = dis.evaluate(X_real, y_real)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 51ms/step - loss: 0.1871 - accuracy: 0.9453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_MYigv8DgzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930e330a-14bf-4f10-97e7-95d1d6493ed7"
      },
      "source": [
        "# Evaluate Generator / Discriminator\n",
        "X_fake, y_fake = generate_img_using_model(gen, BATCH_SIZE)\n",
        "_, acc_fake = dis.evaluate(X_fake, y_fake)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4049 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VrQoxK0EvWI"
      },
      "source": [
        "# Visualize generator result\n",
        "X_test = np.random.randn(10, NOISE_DIM)\n",
        "X_fake = gen.predict(X_test)\n",
        "\n",
        "fig, axs = plt.subplots(2, 5)\n",
        "for i in range(2):\n",
        "    for j in range(5):  \n",
        "        axs[i,j].imshow(np.clip(X_fake[i+j] * 127.5 + 127.5, 0, 255).astype(np.uint8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POSYs-sa_Hrd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}