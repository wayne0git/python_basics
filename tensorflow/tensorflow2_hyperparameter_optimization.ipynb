{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization Example\n",
    "Ref - \n",
    "1. https://towardsdatascience.com/batch-normalization-in-practice-an-example-with-keras-and-tensorflow-2-0-b1ec28bde96f\n",
    "2. https://towardsdatascience.com/tensorboard-hyperparameter-optimization-a51ef7af71f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.25\n",
    "EPOCH = 100\n",
    "\n",
    "# Log Directory\n",
    "LOG_DIR = os.path.join('.', 'logs', 'hp_opt', dt.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "\n",
    "# Hyperparaemters\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64, 128]))\n",
    "HP_BN = hp.HParam('batch_normalization', hp.Discrete([True, False]))\n",
    "HP_BATCH = hp.HParam('batch_size', hp.Discrete([16, 32, 64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Feature Data\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df = df.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Label Data (Label Index 0 ~ 2 => Label String)\n",
    "df['label'] = iris.target\n",
    "df['label'] = df.label.replace(dict(enumerate(iris.target_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label => One-Hot Encoding\n",
    "label = pd.get_dummies(df['label'], prefix='label')\n",
    "df = pd.concat([df, label], axis=1)\n",
    "\n",
    "df.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame => Numpy Array\n",
    "X = np.asarray(df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']])\n",
    "y = np.asarray(df[['label_setosa', 'label_versicolor', 'label_virginica']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log files\n",
    "with tf.summary.create_file_writer(LOG_DIR).as_default():\n",
    "    hp.hparams_config(hparams=[HP_NUM_UNITS, HP_BN, HP_BATCH],\n",
    "                      metrics=[hp.Metric('accuracy', display_name='Acc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def create_model(hparams):\n",
    "    # Create\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(4, ), activation='relu'))\n",
    "    if hparams[HP_BN]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(hparams[HP_NUM_UNITS] * 2, activation='relu'))\n",
    "    if hparams[HP_BN]:\n",
    "        model.add(BatchNormalization())    \n",
    "    model.add(Dense(hparams[HP_NUM_UNITS] * 2, activation='relu'))\n",
    "    if hparams[HP_BN]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    if hparams[HP_BN]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train\n",
    "    h = model.fit(X_train, y_train, batch_size=hparams[HP_BATCH], epochs=EPOCH, \n",
    "                  validation_split=VAL_SIZE, verbose=0)\n",
    "\n",
    "    return h.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        # Record hyperparameter\n",
    "        hp.hparams(hparams)\n",
    "\n",
    "        # Record metric\n",
    "        acc = create_model(hparams)\n",
    "        acc = tf.reshape(tf.convert_to_tensor(acc), []).numpy()\n",
    "        tf.summary.scalar('accuracy', acc, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with different hyperparameter\n",
    "session_num = 0\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for batch_size in HP_BATCH.domain.values:\n",
    "        for bn_layer in HP_BN.domain.values:\n",
    "            hparams = {HP_NUM_UNITS: num_units,\n",
    "                       HP_BATCH: batch_size,\n",
    "                       HP_BN: bn_layer}\n",
    "\n",
    "            print('Run %d' % session_num)\n",
    "            run(os.path.join(LOG_DIR, 'run_%d' % session_num), hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check optimization result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir='./logs/hp_opt/20200719-090551'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
